# Wide Research 详细阶段执行指南

本文档详细说明每个阶段的具体执行步骤、检查点和产出物。

---

## Phase 0: 预执行规划与摸底 (必做)

**核心原则：主控必须亲自完成首轮摸底，不得委托子流程。**

### 0.1 目标明确

```markdown
执行步骤:
1. 分析用户的高层目标
2. 识别潜在风险和资源约束
3. 确定后续扩散所依赖的核心维度
   - 主题簇
   - 相关人物/公司
   - 地域分区
   - 时间切片
   - 技术领域
```

### 0.1.5 两维度分类判断 (必做)

**在摸底阶段必须判断数据来源类型（维度一），输出形态（维度二）可在 Phase 2 细化：**

```markdown
## 维度一判断：数据来源确定性（Phase 0 必须判断）

### 核心问题
"执行这个任务时，是否需要【去找】数据源？"

├── 是，需要搜索/发现 ────→ 🔍 发现型
│   适用规则：严格证据链（≥3条原文/发现）
│
└── 否，数据源已知 ───────→ 📦 处理型
    适用规则：数据完整性优先（≥95%）

### 判断依据
| 特征 | 🔍 发现型 | 📦 处理型 |
|------|----------|----------|
| 数据源 | 未知，需搜索 | 用户已提供 |
| 用户提供URL列表 | 否 | 是 |
| 需要Tavily/搜索 | 是 | 可能不需要 |

### ⚠️ 措辞不决定类型
| 用户说 | 但数据来源是 | 正确判断 |
|-------|-------------|---------|
| "综述最新进展" | 需搜索 | 🔍 发现型 |
| "调研这些文档" | 已知URL | 📦 处理型 |
```

```markdown
## 维度二判断：输出形态（Phase 2 细化）

### 选项
📊 结构化输出：JSON/CSV/表格/可视化
📝 叙事性输出：报告/综述/文档
   └── 可选修饰符：学术风格（作者-年份引用）

### Phase 0 时可初步判断，Phase 2 时最终确定
根据用户需求和任务特征选择，不绑定数据来源类型
```

**向用户确认时说明**：

```markdown
> **任务分类**：
> - 维度一：📦 处理型（数据源已知）
> - 维度二：📊 结构化输出（JSON + 可视化）
>
> 适用规则：
> - 重点关注：数据完整性 ≥95%
> - 原文摘录：可选（数据本身即证据）
```

**规则适用对照**：

| 规则 | 🔍 发现型 | 📦 处理型 |
|------|----------|----------|
| 原文摘录 | ✅ 强制 ≥3条 | ⚠️ 可选 |
| 数据完整性 | ⚠️ 尽力 | ✅ 强制 ≥95% |
| Phase 3.5 验证 | ✅ 完整版 | ⚠️ 简化版 |

---

### 0.2 真实样本获取 (强制)

**必须使用 Tavily MCP 工具进行首次检索：**

```javascript
// 优先使用 tavily_search
mcp__tavily-mcp__tavily_search({
  query: "<用户主题相关查询>",
  max_results: 6,
  search_depth: "advanced",
  include_images: true,
  include_image_descriptions: true
})

// 如需提取页面内容
mcp__tavily-mcp__tavily_extract({
  urls: ["<目标URL>"],
  extract_depth: "advanced"
})
```

**检查点：**
- [ ] 至少获取 1 条与主题直接相关的样本
- [ ] 记录来源 URL、时间、要点
- [ ] 如 Tavily 不可用，记录原因并使用替代方案

### 0.3 初步清单输出

```markdown
## 摸底报告

### 已识别维度
1. **维度A**: [描述]
   - 已掌握选项: [选项1], [选项2]...
   - 样本证据: [引用]

2. **维度B**: [描述]
   - 已掌握选项: ...
   - 样本证据: ...

### 🎯 任务类型分类（关键！）

| 子任务 | 维度一 | 维度二 | 适用规则 |
|-------|--------|--------|---------|
| [子任务1] | 📦 处理型 | 📊 结构化 | 完整性 ≥95% |
| [子任务2] | 🔍 发现型 | 📝 叙事性 | 证据链 ≥3条/发现 |
| [子任务3] | 🔍 发现型 | 📊 结构化 | 证据链 ≥3条/发现 |

> **混合任务说明**：若任务包含多种类型，分别适用对应规则。

### 规模估算
- 预计子任务数量: X
- 预计并行批次: Y
- 预计总耗时: Z 分钟

### 不确定性与缺口
- [待确认事项1]
- [待确认事项2]

### 执行计划概要
- 子任务拆分策略: ...
- 工具与权限: ...
- 输出格式: ...
- 超时策略: ...

### 工作目录
将创建: `runs/YYYYMMDD-<摘要>-<随机6位hex>/`

---
**请确认后回复"执行"或"开始"以继续。**
```

### 0.4 等待用户确认

**关键：在收到明确的"执行/开始"回应前保持等待，不得自动推进。**

---

## Phase 1: 初始化与规划

### 1.1 创建工作目录

```bash
# 生成语义化工作目录
WORK_DIR="runs/$(date +%Y%m%d)-<任务摘要>-$(openssl rand -hex 3)"
mkdir -p "$WORK_DIR"/{raw,prompts,outputs,logs,tmp,cache}

# 目录结构
runs/<日期>-<摘要>-<随机后缀>/
├── raw/              # 原始抓取数据（缓存）
├── prompts/          # 子代理 prompt 文件
├── outputs/          # 子代理输出
├── logs/             # 执行日志
├── tmp/              # 临时文件
├── cache/            # 处理缓存
├── aggregated_raw.md # 聚合原始输出
├── polish_outline.md # 润色大纲
└── final_report.md   # 最终交付物
```

### 1.2 初始化元数据

```bash
# 创建任务元数据文件
cat > "$WORK_DIR/metadata.json" << 'EOF'
{
  "task": "<任务描述>",
  "created_at": "<ISO时间戳>",
  "dimensions": [],
  "subtask_count": 0,
  "status": "initialized"
}
EOF
```

### 1.3 初始化检查点文件（🆕 防止 Auto-Compaction 记忆丢失）

```bash
# 创建检查点文件 - 主 agent 恢复用
cat > "$WORK_DIR/logs/checkpoint.json" << 'EOF'
{
  "current_phase": 1,
  "phase_status": {
    "phase_0": "completed",
    "phase_1": "in_progress",
    "phase_2": "pending",
    "phase_3": "pending",
    "phase_4": "pending",
    "phase_5": "pending"
  },
  "subtasks": {},
  "last_update": "<ISO时间戳>",
  "recovery_hint": "Phase 1 初始化完成，准备进入 Phase 2"
}
EOF

# 创建执行历史文件 - 人类 debug 用（主 agent 不自动读取）
cat > "$WORK_DIR/logs/execution_history.md" << 'EOF'
# Wide Research 执行历史

> ⚠️ 此文件仅供人类 debug 使用，主 agent 不会自动读取以避免上下文膨胀

## Phase 1 - 初始化
- 时间: <ISO时间戳>
- 状态: 工作目录创建完成
- 目录: $WORK_DIR
EOF
```

**检查点设计原则**：

```
┌─────────────────────────────────────────────────────────────────────────┐
│  检查点分层架构（防止 Auto-Compaction 记忆丢失）                            │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  logs/checkpoint.json      ← 主 agent 恢复用（~500 tokens）              │
│  ├── current_phase         # 当前执行到哪个阶段                          │
│  ├── phase_status          # 各阶段完成状态                              │
│  ├── subtasks              # 子任务状态 {"01": "completed", ...}        │
│  ├── last_update           # 最后更新时间                                │
│  └── recovery_hint         # 恢复提示（一句话说明当前状态）                │
│                                                                         │
│  logs/execution_history.md ← 人类 debug 用（不自动读取）                  │
│  └── 完整执行历史，包括每次工具调用和结果                                  │
│                                                                         │
│  ⚠️ 核心原则：                                                          │
│  - checkpoint.json 保持精简（<500 tokens）                               │
│  - 主 agent 恢复时只读 checkpoint.json + outputs/*.md                   │
│  - execution_history.md 仅当人类明确要求时才读取                          │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

---

## Phase 2: 子目标识别与 Prompt 准备

### 2.1 构建子目标列表

```python
# subtasks.json 格式
{
  "subtasks": [
    {
      "id": "subtask_001",
      "name": "调研 GitHub Copilot",
      "dimension": "产品分析",
      "target": "https://github.com/features/copilot",
      "constraints": ["仅分析官方信息", "关注定价和功能"],
      "output_file": "outputs/subtask_001.md"
    },
    // ...更多子任务
  ]
}
```

### 2.2 生成子代理 Prompt 文件

#### ⚠️ 首先：为每个子任务判断两个维度

```
混合型任务分解后，每个子任务独立判断两个维度：

┌─────────────────────────────────────────────────────────────┐
│ 维度一：数据来源确定性（决定证据链规则）                       │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│ 问题：执行此子任务时，是否需要"去找"数据源？                  │
│                                                             │
│ ├── 是，需要搜索 ──────────────────→ 🔍 发现型             │
│ │   验证：证据密度 ≥3                                       │
│ │                                                           │
│ └── 否，数据源已知 ────────────────→ 📦 处理型             │
│     验证：完整性 ≥95%                                       │
├─────────────────────────────────────────────────────────────┤
│ 维度二：输出形态（决定格式模板）                              │
├─────────────────────────────────────────────────────────────┤
│ ├── 📊 结构化输出（JSON/表格/可视化）                        │
│ └── 📝 叙事性输出（报告/综述）                               │
│     └── 可选：学术风格修饰符                                 │
└─────────────────────────────────────────────────────────────┘
```

#### 子任务清单增强格式（含两维度标注）

```python
# subtasks.json 格式（两维度标注）
{
  "subtasks": [
    {
      "id": "subtask_001",
      "name": "调研 GitHub Copilot",
      "source_type": "discovery",   # 🔍 发现型
      "output_format": "narrative", # 📝 叙事性
      "dimension": "产品分析",
      "target": "需搜索发现",
      "constraints": ["证据密度≥3", "原文摘录强制"],
      "output_file": "outputs/subtask_001.md"
    },
    {
      "id": "subtask_006",
      "name": "分析内部 Notion 笔记",
      "source_type": "processing",  # 📦 处理型
      "output_format": "structured", # 📊 结构化
      "dimension": "内部资料",
      "target": ["notion://page1", "notion://page2"],
      "constraints": ["完整性≥95%", "结构化输出"],
      "output_file": "outputs/subtask_006.md"
    }
  ]
}
```

#### 按维度组合选择 Prompt 模板

**🔍 发现型子任务 - 使用证据链模板：**

```bash
# 使用 printf 逐行写入，避免 heredoc 多字节字符问题
SUBTASK_ID="subtask_001"
SUBTASK_NAME="调研 GitHub Copilot"
TARGET_URL="https://github.com/features/copilot"

printf '%s\n' \
  "# 子任务: $SUBTASK_NAME" \
  "" \
  "## 任务类型声明" \
  "⚠️ 本任务为【类型 A：外部调研】，必须遵守证据密度规则。" \
  "" \
  "## 目标" \
  "调研并分析 $SUBTASK_NAME 的关键信息。" \
  "" \
  "## 数据源" \
  "- 主要来源: $TARGET_URL" \
  "" \
  "## 约束" \
  "- 限制 Tavily 搜索不超过 10 轮" \
  "- 必要信息齐全即可结束" \
  "- 【类型 A 强制】每个发现 ≥3 条原文摘录" \
  "" \
  "## 输出格式【强制遵守】" \
  "### 发现 N: [标题]" \
  "**结论**：[1-2句]" \
  "**原文摘录**（≥3条）：" \
  "> \"[原文1]\" —— 来源 [链接](URL)" \
  "> \"[原文2]\" —— 来源 [链接](URL)" \
  "> \"[原文3]\" —— 来源 [链接](URL)" \
  "**分析**：[基于证据的分析]" \
  > "prompts/${SUBTASK_ID}.md"
```

**类型 B 子任务 - 使用数据提取模板：**

```bash
SUBTASK_ID="subtask_006"
SUBTASK_NAME="分析内部 Notion 笔记"
SOURCE_COUNT="20"

printf '%s\n' \
  "# 子任务: $SUBTASK_NAME" \
  "" \
  "## 任务类型声明" \
  "⚠️ 本任务为【类型 B：数据提取】，质量指标为数据完整性。" \
  "" \
  "## 数据源清单" \
  "已知数据源（共 $SOURCE_COUNT 个）" \
  "" \
  "## 约束" \
  "- 【类型 B 强制】完整性目标 ≥95%" \
  "- 每条数据标注来源 URL" \
  "- 无需原文摘录密度要求" \
  "" \
  "## 输出格式" \
  "结构化 JSON + 统计报告" \
  > "prompts/${SUBTASK_ID}.md"
```

### 2.3 Prompt 审阅

```bash
# 主控审阅所有生成的 prompt
for f in prompts/*.md; do
  echo "=== $f ==="
  cat "$f"
  echo ""
done
```

**检查点：**
- [ ] 变量替换正确
- [ ] 指令完整
- [ ] 约束边界清晰

### 2.4 更新检查点（🆕）

**Phase 2 完成后必须更新检查点：**

```bash
# 更新 checkpoint.json
cat > "$WORK_DIR/logs/checkpoint.json" << 'EOF'
{
  "current_phase": 2,
  "phase_status": {
    "phase_0": "completed",
    "phase_1": "completed",
    "phase_2": "completed",
    "phase_3": "pending",
    "phase_4": "pending",
    "phase_5": "pending"
  },
  "subtasks": {
    "subtask_01": "pending",
    "subtask_02": "pending",
    ...
  },
  "subtask_count": X,
  "last_update": "<ISO时间戳>",
  "recovery_hint": "Phase 2 完成，已生成 X 个子任务 prompt，准备启动并行执行"
}
EOF

# 追加执行历史
cat >> "$WORK_DIR/logs/execution_history.md" << 'EOF'

## Phase 2 - Prompt 准备
- 时间: <ISO时间戳>
- 子任务数量: X
- 生成文件: prompts/subtask_01.md, prompts/subtask_02.md, ...
EOF
```

---

## Phase 3: 并行执行 (关键步骤)

### 3.1 Claude Code Task Tool 并行模式

**核心原则：所有独立子任务必须在单条消息中启动！**

```javascript
// ✅ 正确：单条消息启动所有子代理
[Single Message]:
  Task("调研产品A", "...<完整prompt>...", "researcher", { model: "haiku", run_in_background: true })
  Task("调研产品B", "...<完整prompt>...", "researcher", { model: "haiku", run_in_background: true })
  Task("调研产品C", "...<完整prompt>...", "researcher", { model: "haiku", run_in_background: true })
  Task("调研产品D", "...<完整prompt>...", "researcher", { model: "haiku", run_in_background: true })

// ❌ 错误：多条消息串行启动
Message 1: Task("调研产品A", ...)
Message 2: Task("调研产品B", ...)  // 这会打破并行！
```

### 3.2 子代理类型选择

| 任务类型 | 推荐 Agent Type | 说明 |
|---------|----------------|------|
| 信息调研 | `researcher` | 深度研究和信息收集 |
| 代码分析 | `code-analyzer` | 代码库探索和分析 |
| 数据提取 | `Explore` | 快速探索和提取 |
| 综合任务 | `general-purpose` | 通用多步骤任务 |

### 3.3 超时与重试策略

```javascript
// 子代理内置超时处理
Task("调研任务", `
  ## 时间约束
  - 总执行时间不超过 5 分钟
  - 如 5 分钟内未完成，输出当前进度并标记 [TIMEOUT]

  ## 重试策略
  - 网络请求失败时最多重试 2 次
  - 重试失败后记录错误原因，不阻塞其他步骤

  ## 失败处理
  如无法完成任务，输出以下格式：

  ## 失败报告
  - 失败原因: [具体原因]
  - 已完成部分: [列出]
  - 后续建议: [建议]
`, "researcher")
```

### 3.4 进度监控

```javascript
// 使用 TodoWrite 追踪所有子任务
TodoWrite([
  { content: "子任务1: 调研产品A", status: "in_progress", activeForm: "调研产品A" },
  { content: "子任务2: 调研产品B", status: "in_progress", activeForm: "调研产品B" },
  { content: "子任务3: 调研产品C", status: "in_progress", activeForm: "调研产品C" },
  // ...
])

// 子任务完成后更新状态
// 使用 TaskOutput 获取简短状态（不是完整内容）
```

### 3.5 子代理输出策略（防止上下文溢出）

**⚠️ 关键规则：子代理必须将完整输出写入文件，只返回简短状态！**

```
问题：
- 启动 19 个子代理，每个返回 2000-5000 tokens
- 主控上下文被填满 → "Context low · Run /compact" 错误

解决方案：
子代理 Prompt 必须包含以下输出指令：

## 输出方式【强制遵守】

1. 将完整调研结果写入指定文件：
   Write("$WORK_DIR/outputs/subtask_XXX.md", <完整内容>)

2. 最后只返回简短状态摘要（≤200字）：
   ## 完成状态
   - 状态: ✅ 成功 / ⚠️ 部分完成 / ❌ 失败
   - 输出文件: outputs/subtask_XXX.md
   - 字数: XXXX
   - 发现数/数据条数: X
   - 证据密度/完整性: X.X / X%

⛔ 禁止在返回消息中包含完整调研内容！
```

**效果对比**：

| 策略 | 单个子代理返回 | 19 个子代理总计 | 结果 |
|------|--------------|---------------|------|
| ❌ 返回完整内容 | ~3000 tokens | ~57000 tokens | 上下文溢出 |
| ✅ 只返回状态 | ~50 tokens | ~1000 tokens | 安全 |

### 3.6 🆕 子代理增量写入模式（防止 Auto-Compaction 内容丢失）

**问题根因**：

```
┌─────────────────────────────────────────────────────────────────────────┐
│  子代理 Auto-Compaction 风险                                             │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  ❌ 当前模式（危险）：                                                   │
│  ┌─────────────────────────────────────────────────────────────────┐   │
│  │  子代理执行 8 轮检索 → 在内存中积累所有发现 → 最后一次性写入文件    │   │
│  │                                                                   │   │
│  │  风险：如果第 6 轮发生 compaction，第 1-5 轮的发现全部丢失          │   │
│  └─────────────────────────────────────────────────────────────────┘   │
│                                                                         │
│  ✅ 增量写入模式（安全）：                                              │
│  ┌─────────────────────────────────────────────────────────────────┐   │
│  │  第 1 轮检索 → 发现 1 → 立即追加写入 outputs/subtask_XX.md         │   │
│  │  第 2 轮检索 → 发现 2 → 立即追加写入 outputs/subtask_XX.md         │   │
│  │  第 3 轮检索 → 发现 3 → 立即追加写入 outputs/subtask_XX.md         │   │
│  │  ...                                                              │   │
│  │  🔴 第 6 轮发生 compaction                                         │   │
│  │  ...                                                              │   │
│  │  但发现 1-5 已经安全写入文件！不会丢失！                            │   │
│  └─────────────────────────────────────────────────────────────────┘   │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

**子代理 Prompt 必须包含以下增量写入指令**：

```markdown
## 增量写入模式【强制遵守】

⚠️ 为防止 auto-compaction 导致内容丢失，必须采用增量写入：

### 执行流程
1. **首次写入**：完成第一个发现后，立即创建输出文件
   ```
   Write("$WORK_DIR/outputs/subtask_XX.md", <文件头 + 发现1>)
   ```

2. **后续追加**：每完成一个发现，立即追加到文件
   ```
   Edit("$WORK_DIR/outputs/subtask_XX.md",
        old_string="---\n\n## 证据汇总表",
        new_string="---\n\n### 发现 N: [新发现]\n...\n\n---\n\n## 证据汇总表")
   ```

3. **写入前检查**：避免重复内容
   - 读取文件头部检查已有发现数量
   - 新发现编号 = 已有发现数 + 1

### 文件结构（支持增量追加）

```markdown
# 子任务: [名称]

## ⚠️ 格式合规声明
本输出采用增量写入模式，每个发现完成后立即写入。

---

### 发现 1: [标题]
[内容...]

---

### 发现 2: [标题]
[内容...]

---

## 证据汇总表
| # | 原文摘要 | 来源 | URL |
|---|---------|------|-----|
[此表在最后统一更新]

## 完成状态
- 发现数: X
- 证据密度: X.X
```

### 关键规则
- ✅ 每完成一个发现，立即写入文件
- ✅ 使用 Edit 工具追加内容（在"证据汇总表"前插入）
- ✅ 证据汇总表在最后统一更新
- ❌ 禁止在内存中积累所有发现后一次性写入
- ❌ 禁止覆盖已有内容（用 Edit 追加，非 Write 覆盖）
```

### 3.7 更新检查点（Phase 3 完成后）

**每个子任务完成时更新检查点**：

```bash
# 子任务完成后，更新 checkpoint.json 中的 subtasks 状态
# 使用 Edit 工具更新特定字段，而非重写整个文件

# 示例：标记 subtask_01 为完成
Edit("$WORK_DIR/logs/checkpoint.json",
     old_string='"subtask_01": "pending"',
     new_string='"subtask_01": "completed"')

# 更新 last_update 时间戳
Edit("$WORK_DIR/logs/checkpoint.json",
     old_string='"last_update": "旧时间戳"',
     new_string='"last_update": "新时间戳"')
```

**Phase 3 完全完成后更新检查点**：

```bash
cat > "$WORK_DIR/logs/checkpoint.json" << 'EOF'
{
  "current_phase": 3,
  "phase_status": {
    "phase_0": "completed",
    "phase_1": "completed",
    "phase_2": "completed",
    "phase_3": "completed",
    "phase_4": "pending",
    "phase_5": "pending"
  },
  "subtasks": {
    "subtask_01": "completed",
    "subtask_02": "completed",
    ...
  },
  "subtask_count": X,
  "completed_count": Y,
  "failed_count": Z,
  "last_update": "<ISO时间戳>",
  "recovery_hint": "Phase 3 完成，Y/X 子任务成功，准备进入聚合阶段"
}
EOF
```

---

## 🔴 Phase 3.5: 子代理输出验证（强制步骤）

**此步骤是解决"子代理没有遵守原文摘录要求"的关键控制点。**

### 3.5.1 单个子任务验证

对每个子任务输出执行以下检查：

```markdown
## 验证清单 - 子任务 [名称]

### 原文存在性
- [ ] 输出包含 > "..." 格式的原文摘录
- [ ] 原文使用引号包裹
- [ ] 原文后有来源标注

### 原文数量
- [ ] 发现 1 有 ≥3 条原文
- [ ] 发现 2 有 ≥3 条原文
- [ ] 发现 3 有 ≥3 条原文

### 原文质量
- [ ] 原文是直接引用，非改写
- [ ] 每条原文有可点击 URL

### 统计
- 发现数: ___
- 原文总数: ___
- 密度: ___
```

### 3.5.2 验证失败处理

```
失败类型 → 处理方式

1. 完全无原文 → 退回重做 或 标记"无效输出"
2. 原文不足   → 标记"证据不完整"，继续聚合
3. 原文改写   → 退回要求提取原文
4. 缺少 URL   → 主控补充 或 标注"来源待验证"
```

### 3.5.3 批量验证汇总

```markdown
## 子代理输出验证汇总

| 子任务 | 发现数 | 原文数 | 密度 | 状态 |
|-------|-------|-------|------|------|
| 任务1 | _ | _ | _ | ✅/⚠️/❌ |
| 任务2 | _ | _ | _ | ✅/⚠️/❌ |
| ... | ... | ... | ... | ... |

**验证结论**:
- ✅ 通过任务数: ___
- ⚠️ 不完整任务数: ___
- ❌ 无效任务数: ___

**是否可进入 Phase 4**: [是/否]
- 若无效任务 > 20%，需退回补充
```

### 3.5.4 验证检查点（强制）

**不得跳过此检查点进入 Phase 4！**

```
检查点判定：

通过条件（同时满足）：
1. ≥80% 子任务输出包含原文摘录
2. 平均证据密度 ≥ 2.0
3. 无完全无效的子任务（或已标记排除）

不通过则：
- 退回问题子任务重新执行
- 或主控亲自补充验证
- 或将问题子任务标记为"证据不足"
```

---

## Phase 4: 程序化聚合

### ⚠️ 核心原则 1：从文件读取，非 TaskOutput

```
重要变更（配合 Phase 3.5 防止上下文溢出）：

聚合数据来源：
❌ 错误：从 TaskOutput 获取子代理的完整输出
✅ 正确：从 $WORK_DIR/outputs/subtask_XXX.md 文件读取

流程：
1. TaskOutput 只返回简短状态（≤200字）
2. 检查状态确认子代理成功写入文件
3. 聚合脚本直接读取 outputs/ 目录下的所有 .md 文件
```

### ⚠️ 核心原则 2：聚合 ≠ 压缩

```
聚合的目的是【整合】而非【压缩】

❌ 错误的聚合：
子任务输出 5 条原文摘录 → 聚合后变成 1 句总结

✅ 正确的聚合：
子任务输出 5 条原文摘录 → 聚合后分类整理，5 条全部保留
```

**强制规则：**
1. **禁止丢弃原文摘录** - 所有子任务中的直接引用必须保留
2. **禁止过度概括** - 不得将多条具体证据合并为一个模糊结论
3. **可以重新组织** - 按主题/维度重新分类是允许的
4. **可以去重** - 完全相同的引用可以合并（保留一个）

### 4.1 收集子代理状态（非完整输出）

```javascript
// ✅ 正确：TaskOutput 只获取简短状态
const status1 = TaskOutput("subtask_001_id");
// 返回内容示例（≤200字）：
// ## 完成状态
// - 状态: ✅ 成功
// - 输出文件: outputs/subtask_001.md
// - 字数: 3245
// - 发现数: 5
// - 证据密度: 3.4

// ❌ 错误：期望从 TaskOutput 获取完整调研内容
// 这会导致上下文溢出！
```

### 4.2 验证输出文件存在

```bash
# 检查所有子代理是否已写入输出文件
ls -la "$WORK_DIR/outputs/"

# 预期输出：
# subtask_001.md (3.2K)
# subtask_002.md (2.8K)
# subtask_003.md (4.1K)
# ...

# 统计成功写入的文件数
echo "成功输出文件数: $(ls $WORK_DIR/outputs/*.md 2>/dev/null | wc -l)"
```

### 4.3 运行聚合脚本

```bash
# 使用内置聚合脚本（从文件读取，非 TaskOutput）
python .claude/skills/wide-research/scripts/aggregate.py \
  --input-dir "$WORK_DIR/outputs" \
  --output "$WORK_DIR/aggregated_raw.md" \
  --format markdown \
  --preserve-quotes  # 强制保留原文摘录
```

### 4.4 聚合质量检查

在生成 aggregated_raw.md 后，必须验证：

```markdown
## 聚合质量检查清单

- [ ] 原文摘录数量：聚合后 ≥ 子任务输出总和的 80%
- [ ] 每个核心发现仍有 ≥3 条原文支撑
- [ ] 来源标注完整（出处 + URL）
- [ ] 无"孤立结论"（没有证据支撑的陈述）
```

### 4.5 聚合输出格式

```markdown
# 聚合报告 - <任务名称>

生成时间: <ISO时间戳>
子任务数量: X
成功: Y | 失败: Z

---

## 子任务 1: <名称>
状态: ✅ 成功 / ❌ 失败 / ⚠️ 部分完成

<子任务输出内容>

---

## 子任务 2: <名称>
...

---

## 聚合统计
- 总引用数: X
- 覆盖维度: [列表]
- 缺失维度: [列表]
- 质量评估: [评分/说明]
```

---

## Phase 5: 分章润色与交付

### 5.1 设计章节大纲

```markdown
# polish_outline.md

## 目标受众
[描述]

## 章节结构

### 1. 执行摘要
- 核心论点: ...
- 素材来源: 子任务 1, 3, 5

### 2. 背景与方法
- 核心论点: ...
- 素材来源: 摸底阶段

### 3. 主要发现
#### 3.1 维度A分析
- 核心论点: ...
- 素材来源: 子任务 2, 4

#### 3.2 维度B分析
...

### 4. 洞察与建议
...

### 5. 附录
- 数据来源
- 方法说明
```

### 5.2 逐章撰写精修稿

**关键原则：**
1. **逐章迭代** - 每完成一章立即自查
2. **保持上下文** - 避免一次性重写
3. **核实引用** - 回溯子稿确认事实

```markdown
## 撰写检查清单（每章）

- [ ] 事实准确，与子任务输出一致
- [ ] 引用格式正确 [来源](URL)
- [ ] 语言符合目标受众
- [ ] 与前后章节衔接顺畅
- [ ] 无重复信息
- [ ] 保留关键量化数据
```

### 5.3 双重质检

**质检 1: 结构检查**
```
问题: 成稿是否通过分章节、多轮整合完成？
- 是 → 继续质检2
- 否 → 退回按章节重写
```

**质检 2: 深度检查**
```
问题: 全文是否足够详实？
- 是 → 继续 5.3.5 证据链验证
- 否 → 判断原因:
  - 子任务素材不足 → 补充调研
  - 统稿压缩过度 → 扩展润色
```

### 🔴 5.3.5 证据链保留验证（强制步骤）

**⚠️ 此步骤解决"润色阶段证据链丢失"的核心问题。不得跳过！**

#### 问题根因

```
子代理输出: 每产品 ~15-20 条原文摘录（带URL）
最终报告: 仅剩 ~2-3 条数据引用（无URL）

根因: 润色时选择了"干净的报告"而不是"可验证的报告"
```

#### 5.3.5.1 计算证据链保留率

**润色完成后，必须执行以下验证：**

```bash
# 统计子代理原文摘录总数
SUBAGENT_QUOTES=$(grep -c '> "' $WORK_DIR/outputs/*.md | awk -F: '{sum+=$2} END {print sum}')

# 统计最终报告原文摘录数
REPORT_QUOTES=$(grep -c '> "' $WORK_DIR/final_report.md)

# 计算保留率
RETENTION_RATE=$(echo "scale=2; $REPORT_QUOTES / $SUBAGENT_QUOTES * 100" | bc)

echo "证据链保留率: $RETENTION_RATE%"
```

#### 5.3.5.2 验证指标与通过标准

| 检查项 | 计算方式 | 通过标准 | 当前值 |
|-------|---------|---------|-------|
| 证据链保留率 | 最终报告原文数 / 子代理原文总数 | **≥30%** | ___ |
| 报告证据密度 | 最终报告原文数 / 核心发现数 | **≥2.0** | ___ |
| URL 保留率 | 最终报告URL数 / 子代理URL总数 | **≥50%** | ___ |

#### 5.3.5.3 验证失败处理

**若任一指标不通过，必须采用"三层报告结构"重写：**

```markdown
# 最终报告（三层结构）

## 第一层：核心洞察（快速阅读）
[1-2 句核心结论，无需证据]

## 第二层：证据支撑（每个洞察下可折叠）
<details>
<summary>📚 支撑证据（点击展开）</summary>

**原文摘录**：
> "[原文1]" —— 来源 [链接](URL)
> "[原文2]" —— 来源 [链接](URL)
> "[原文3]" —— 来源 [链接](URL)

</details>

## 第三层：完整素材（链接到子代理输出）
详细原始数据请查看：[outputs/](outputs/) 目录
```

#### 5.3.5.4 三层结构示例

```markdown
## 发现 1：GitHub Copilot 市场领先

**核心洞察**：GitHub Copilot 以 180 万+月活用户和 77,000+ 企业客户占据市场领导地位。

<details>
<summary>📚 支撑证据（3条）</summary>

> "GitHub Copilot now has more than 1.8 million active users and over 77,000 organizations paying for it." —— [GitHub Blog](https://github.blog/news-insights/...)

> "Copilot has become the most widely adopted AI developer tool." —— [TechCrunch](https://techcrunch.com/...)

> "Microsoft reported that GitHub Copilot revenue grew over 40% quarter-over-quarter." —— [Microsoft Q4 Earnings](https://microsoft.com/...)

</details>

**分析**：先发优势 + 微软生态整合是核心护城河。
```

#### 5.3.5.5 验证检查点

```
┌─────────────────────────────────────────────────────────────────────────┐
│  ⛔ 证据链保留验证检查点（润色后、交付前必做）                            │
├─────────────────────────────────────────────────────────────────────────┤
│  通过条件（全部满足）：                                                  │
│  1. 证据链保留率 ≥ 30%                                                  │
│  2. 报告证据密度 ≥ 2.0                                                  │
│  3. URL 保留率 ≥ 50%                                                    │
│                                                                         │
│  不通过则：                                                             │
│  1. 采用"三层报告结构"重写                                              │
│  2. 使用 <details> 可折叠区域保留完整证据链                              │
│  3. 重新计算指标直到通过                                                │
└─────────────────────────────────────────────────────────────────────────┘
```

### 5.4 最终交付

```markdown
## 交付物

最终报告已生成: `runs/<工作目录>/final_report.md`

### ✅ 验证确认
- [x] Phase 3.5 子代理输出验证：X/Y 通过，证据密度 Z.Z
- [x] Phase 5.5 交付前自审：数据条目数(N) = 显示条目数(N)
- [x] 📦 处理型子任务完整性：X/Y 成功 (Z%)
- [x] 🔍 发现型子任务证据链：平均密度 Z.Z

### 核心结论
1. [结论1]
2. [结论2]
3. [结论3]

### 可执行建议
- [建议1]
- [建议2]

### 🔄 建议后续
基于本轮调研，以下方向可能值得深入：

| 深入方向 | 原因 | 触发方式 |
|---------|------|---------|
| [对象A vs 对象B 详细对比] | [两者在某维度差异最大] | 说"深入对比 A 和 B" |
| [对象C 技术架构分析] | [信息较少但潜力大] | 说"深入调研 C" |
| [维度X 补充调研] | [本轮覆盖不足] | 说"补充调研 X" |

*如需深入，直接告诉我即可，我会继承本轮上下文。*

### 待确认事项
- [事项1] - 建议后续跟进方式: ...

---
完整报告请查看: [final_report.md](runs/<工作目录>/final_report.md)
```

**⚠️ "建议后续"生成规则**：

| 条件 | 是否生成 |
|------|---------|
| 调研发现明显对比机会（如两产品差异大） | ✅ 必须生成 |
| 某对象信息不足但有潜力 | ✅ 必须生成 |
| 用户目标暗示需深入（如"选型"）| ✅ 必须生成 |
| 用户只需概览，无后续决策需求 | ⚠️ 可省略 |
| 所有对象覆盖均衡，无深入价值 | ⚠️ 可省略 |

### 5.4.1 建议后续的生成规则

**何时生成建议后续表格：**
- 当调研发现明显的对比机会（如两个产品用户评价差异大）
- 当某个对象信息不足但潜力值得关注
- 当用户的原始目标暗示可能需要深入（如"选型"暗示需要详细对比）

**何时省略：**
- 用户只需要概览，没有后续决策需求
- 本轮调研已经足够详细
- 所有对象信息覆盖均衡，无明显深入价值

**建议后续的设计原则：**
1. **有依据**：每条建议必须基于本轮调研的具体发现
2. **可操作**：用户只需说一句话即可触发
3. **不强制**：这是可选区块，不是每次都需要
4. **继承上下文**：深入调研时无需重复解释背景

---

## 🔴 Phase 5.5: 交付前自审（强制步骤）

**在向用户展示报告前，必须完成此自审步骤！**

### 5.5.1 为什么需要自审

```
数据正确 ≠ 呈现正确

常见的"最后一公里"问题：
- 数据管道成功（JSON 有 45 条数据）
- 但前端只显示 4 条（CSS max-height 限制）

用户看到的是呈现结果，不是数据管道！
```

### 5.5.2 自审检查清单

**对于所有类型的最终报告，必须检查：**

```markdown
## 交付前自审清单

### 数据-呈现一致性（最重要！）
- [ ] 报告中声明的数据总数 = 实际可见/可访问的数据条数
- [ ] 列表/表格的行数 = 源数据的条目数
- [ ] 可折叠区域展开后内容完整
- [ ] 统计数字与实际列表匹配

### 交互功能验证
- [ ] 所有可折叠区域能正常展开/收起
- [ ] 展开后的内容没有被截断
- [ ] 如有分页，所有页面都能访问
- [ ] 如有搜索/筛选，功能正常工作

### 视觉完整性
- [ ] 无内容被 CSS overflow 截断
- [ ] 长列表能完整显示（或有有效的滚动）
- [ ] 图表/可视化正确加载
```

### 5.5.3 快速验证方法

**若报告使用 JavaScript 动态渲染：**

```javascript
// 在浏览器控制台执行

// 1. 检查数据总数
console.log("数据数组长度:", dataArray.length);

// 2. 检查实际渲染的元素数
console.log("DOM 元素数:", document.querySelectorAll('.item').length);

// 3. 两者必须相等！
if (dataArray.length !== document.querySelectorAll('.item').length) {
  console.error("⚠️ 数据与显示不一致！");
}
```

### 5.5.4 自审失败处理

```
发现问题 → 处理流程

1. 数据与显示不一致
   → 检查 CSS（max-height, overflow）
   → 检查 JS 渲染逻辑
   → 修复后重新生成报告

2. 内容被截断
   → 调整容器高度或样式
   → 或改用分页/虚拟滚动

3. 交互功能异常
   → 检查 JS 事件绑定
   → 修复后验证所有交互路径
```

### 5.5.5 自审通过标准

```
✅ 可以交付的条件：
1. 数据条目数 = 可见/可访问条目数
2. 所有交互组件工作正常
3. 无内容截断问题
4. 统计数字与实际列表一致

⛔ 禁止交付的情况：
1. 声明"45条数据"但只显示4条
2. 可折叠区域展开后为空或不完整
3. 存在被截断的内容区域
4. 统计数字与实际列表不匹配
```

---

## 阶段转换检查点

```
Phase 0 → Phase 1: 用户确认"执行/开始"
Phase 1 → Phase 2: 工作目录创建成功 + checkpoint.json 初始化
Phase 2 → Phase 3: 所有 prompt 文件审阅通过 + checkpoint 更新
Phase 3 → Phase 4: 所有子任务完成或超时 + checkpoint 更新
Phase 4 → Phase 5: 聚合文件生成成功 + checkpoint 更新
Phase 5 → 交付:  双重质检通过 + 最终 checkpoint 更新
```

---

## 🆕 Auto-Compaction 恢复流程

当主 agent 发生 auto-compaction 后，使用以下流程恢复状态：

### 恢复步骤

```markdown
## Auto-Compaction 恢复检查清单

1. **读取检查点**
   ```bash
   cat "$WORK_DIR/logs/checkpoint.json"
   ```

2. **确定当前阶段**
   - 检查 `current_phase` 字段
   - 检查 `phase_status` 确认哪些阶段已完成

3. **恢复子任务状态**
   - 检查 `subtasks` 字段，识别已完成/进行中/待执行的子任务
   - 读取已完成子任务的输出：`cat $WORK_DIR/outputs/subtask_*.md`

4. **继续执行**
   - 跳过已完成的阶段
   - 从 `recovery_hint` 获取下一步行动建议

5. **更新检查点**
   - 恢复后立即更新 `last_update` 时间戳
```

### 恢复场景示例

```
场景 1：Phase 3 执行中发生 compaction

checkpoint.json 显示：
{
  "current_phase": 3,
  "subtasks": {
    "subtask_01": "completed",
    "subtask_02": "completed",
    "subtask_03": "in_progress",
    "subtask_04": "pending"
  },
  "recovery_hint": "正在执行 subtask_03"
}

恢复行动：
1. 读取 outputs/subtask_01.md 和 outputs/subtask_02.md 了解已完成内容
2. 检查 subtask_03 是否已写入部分内容（增量写入模式）
3. 继续执行 subtask_03 和 subtask_04
```

### 关键原则

```
┌─────────────────────────────────────────────────────────────────────────┐
│  恢复原则                                                               │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  1. 只读 checkpoint.json（~500 tokens）                                 │
│     ❌ 不读 execution_history.md（除非人类要求）                         │
│                                                                         │
│  2. 按需读取 outputs/*.md                                               │
│     只读取需要继续工作的子任务输出                                       │
│                                                                         │
│  3. 不重复已完成工作                                                    │
│     依赖检查点状态跳过已完成步骤                                         │
│                                                                         │
│  4. 恢复后立即更新检查点                                                │
│     防止下次 compaction 导致重复恢复                                     │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```
